{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adf0e2f4",
   "metadata": {},
   "source": [
    "# Document Loading\n",
    "\n",
    "<img src=\"./images/L1-Document_loading.png\" alt=\"Document Loading\"></img>\n",
    "\n",
    "<hr/>\n",
    "<img src=\"./images/L1_documentLoad.png\" alt=\"Document Loading\"></img>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3038ef6a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Retrieval augmented generation\n",
    "\n",
    "In retrieval augmented generation (RAG), an LLM retrieves contextual documents from an external dataset as part of its execution.\n",
    "\n",
    "This is useful if we want to ask question about specific documents (e.g., our PDFs, a set of videos, etc).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41284636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8c5b67",
   "metadata": {},
   "source": [
    "## PDFs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e21479aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pypdf "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8d3b72",
   "metadata": {},
   "source": [
    "Each page is a Document.\n",
    "\n",
    "A Document contains **text (page_content)** and **metadata**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c29cf24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "22\n",
      "MachineLearning-Lecture01  \n",
      "Instructor (Andrew Ng):  Okay. Good morning. Welcome to CS229, the machine \n",
      "learning class. So what I wanna do today is ju st spend a little time going over the logistics \n",
      "of the class, and then we'll start to  talk a bit about machine learning.  \n",
      "By way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class. And so \n",
      "I personally work in machine learning, and I' ve worked on it for about 15 years now, and \n",
      "I actually think that machine learning i\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the PyPDFLoader class from the langchain.document_loaders module\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Create an instance of PyPDFLoader with the path to the PDF file\n",
    "loader = PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\")\n",
    "\n",
    "# Load the pages of the PDF document into a variable\n",
    "pages = loader.load()\n",
    "\n",
    "# Print the type of the loaded pages (should be a list or similar structure)\n",
    "print(type(pages))\n",
    "\n",
    "# Print the number of pages loaded from the PDF document\n",
    "print(len(pages))\n",
    "\n",
    "# Access the first page of the loaded PDF\n",
    "page = pages[0] \n",
    "\n",
    "# Print the first 500 characters of the content from the first page\n",
    "print(page.page_content[0:500])\n",
    "\n",
    "# Print the metadata associated with the first page\n",
    "page.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2817343a",
   "metadata": {},
   "source": [
    "## YouTube\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b848b13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bac025b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yt_dlp\n",
      "  Downloading yt_dlp-2024.8.6-py3-none-any.whl.metadata (170 kB)\n",
      "     ---------------------------------------- 0.0/170.1 kB ? eta -:--:--\n",
      "     ------ ------------------------------ 30.7/170.1 kB 435.7 kB/s eta 0:00:01\n",
      "     --------------- --------------------- 71.7/170.1 kB 787.7 kB/s eta 0:00:01\n",
      "     --------------- --------------------- 71.7/170.1 kB 787.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 170.1/170.1 kB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: brotli in c:\\users\\abhin\\anaconda3\\lib\\site-packages (from yt_dlp) (1.0.9)\n",
      "Requirement already satisfied: certifi in c:\\users\\abhin\\appdata\\roaming\\python\\python312\\site-packages (from yt_dlp) (2024.8.30)\n",
      "Collecting mutagen (from yt_dlp)\n",
      "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pycryptodomex (from yt_dlp)\n",
      "  Downloading pycryptodomex-3.20.0-cp35-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.32.2 in c:\\users\\abhin\\appdata\\roaming\\python\\python312\\site-packages (from yt_dlp) (2.32.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.17 in c:\\users\\abhin\\appdata\\roaming\\python\\python312\\site-packages (from yt_dlp) (2.2.2)\n",
      "Collecting websockets>=12.0 (from yt_dlp)\n",
      "  Downloading websockets-13.0.1-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abhin\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.32.2->yt_dlp) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhin\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.32.2->yt_dlp) (3.8)\n",
      "Downloading yt_dlp-2024.8.6-py3-none-any.whl (3.1 MB)\n",
      "   ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/3.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.2/3.1 MB 2.8 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.2/3.1 MB 2.4 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.3/3.1 MB 1.7 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.3/3.1 MB 1.7 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.4/3.1 MB 1.7 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.5/3.1 MB 1.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.6/3.1 MB 1.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.7/3.1 MB 1.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.8/3.1 MB 1.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.9/3.1 MB 1.7 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.9/3.1 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 1.0/3.1 MB 1.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 1.1/3.1 MB 1.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.2/3.1 MB 1.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 1.4/3.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.5/3.1 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.6/3.1 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.6/3.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.8/3.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.9/3.1 MB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.0/3.1 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.2/3.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.2/3.1 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.4/3.1 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.4/3.1 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.5/3.1 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.6/3.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.7/3.1 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.9/3.1 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.1/3.1 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.1/3.1 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.1/3.1 MB 2.1 MB/s eta 0:00:00\n",
      "Downloading websockets-13.0.1-cp312-cp312-win_amd64.whl (152 kB)\n",
      "   ---------------------------------------- 0.0/152.2 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 71.7/152.2 kB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 152.2/152.2 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
      "   ---------------------------------------- 0.0/194.4 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 112.6/194.4 kB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 184.3/194.4 kB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 194.4/194.4 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading pycryptodomex-3.20.0-cp35-abi3-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/1.8 MB 2.0 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.3/1.8 MB 2.6 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.3/1.8 MB 3.0 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.4/1.8 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.8 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.8 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.7/1.8 MB 2.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.9/1.8 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.0/1.8 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.2/1.8 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.3/1.8 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.5/1.8 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.6/1.8 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.7/1.8 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.7/1.8 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 2.3 MB/s eta 0:00:00\n",
      "Installing collected packages: websockets, pycryptodomex, mutagen, yt_dlp\n",
      "Successfully installed mutagen-1.47.0 pycryptodomex-3.20.0 websockets-13.0.1 yt_dlp-2024.8.6\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "! pip install yt_dlp\n",
    "! pip install pydub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ea326e",
   "metadata": {},
   "source": [
    "**Note**: This can take several minutes to complete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358b0603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL of the YouTube video to be processed\n",
    "url = \"https://www.youtube.com/watch?v=jGwO_UgTS7I\"\n",
    "\n",
    "# Specify the directory where the audio will be saved\n",
    "save_dir = \"docs/youtube/\"\n",
    "\n",
    "# Initialize a GenericLoader with a YoutubeAudioLoader for the specified URL and save directory,\n",
    "# and an OpenAIWhisperParser for processing the audio\n",
    "loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url], save_dir),\n",
    "    OpenAIWhisperParser()\n",
    ")\n",
    "\n",
    "# Load the documents (audio content) from the specified YouTube video\n",
    "docs = loader.load()\n",
    "\n",
    "# Display the first 500 characters of the page content from the first document\n",
    "docs[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d02460",
   "metadata": {},
   "source": [
    "## URLs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09434f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://github.com/basecamp/handbook/blob/master/37signals-is-you.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "668d6e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7708cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "handbook/37signals-is-you.md at master · basecamp/handbook · GitHub\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Toggle navigation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            Sign up\n",
      "          \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        Product\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Actions\n",
      "        Automate any workflow\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Packages\n",
      "        Host and manage packages\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Security\n",
      "        Find and fix vulnerabilities\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cod\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90673a7",
   "metadata": {},
   "source": [
    "## Notion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70a079e",
   "metadata": {},
   "source": [
    "Follow steps [here](https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/notion) for an example Notion site such as [this one](https://yolospace.notion.site/Blendle-s-Employee-Handbook-e31bff7da17346ee99f531087d8b133f):\n",
    "\n",
    "- Duplicate the page into your own Notion space and export as Markdown / CSV.\n",
    "- Unzip it and save it as a folder that contains the markdown file for the Notion page.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd29f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "loader = NotionDirectoryLoader(\"docs/Notion_DB\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415bc771",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899134d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
